{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+xENbreCYtKcG4tGEQnvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilakalikiri/Shala_learning/blob/main/module1_DataScience/Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas tutorial\n",
        "\"\"\"\n",
        "importing data sets only columns or rows\n",
        "pandas series\n",
        "pandas head and tail\n",
        "loc and iloc\n",
        "index\n",
        "filters\n",
        "\"\"\"\n",
        "#importing pandas\n",
        "\n",
        "import pandas as pd\n",
        "print(pd.options.display.max_rows) #prints max amount of rows which your computer supports\n",
        "pd.options.display.max_rows=9999    #sets max capacity of your computer\n",
        "print(pd.options.display.max_rows)\n",
        "#importing data\n",
        "df=pd.read_csv(\"survey_results_public.csv\")\n",
        "df=pd.read_csv(\"survey_results_public.csv\",skiprows=1)\n",
        "df=pd.read_csv(\"survey_results_public.csv\",header=1)\n",
        "\n",
        "data=pd.DataFrame(df,columns=['Respondent','Trans','Age','Gender'])\n",
        "print(data)\n",
        "\n",
        "\n",
        "# creating a Series\n",
        "#series is like a column in pandas\n",
        "x=[1,2,3]\n",
        "var=pd.Series(x)\n",
        "print(x)\n",
        "# creating data frames\n",
        "#Data frame is 2 dimensional structure\n",
        "\n",
        "# method 1 by dictinary\n",
        "\n",
        "a={\"1\":[\"a\",\"one\"],\n",
        "  \"2\":[\"b\",\"two\"]}\n",
        "\n",
        "df1=pd.DataFrame(a)\n",
        "print(df1)\n",
        "# method 2 using tuples\n",
        "\n",
        "b=[(1,2,3),(4,5,6)]\n",
        "df2=pd.DataFrame(b,index=[\"x\",\"y\"])\n",
        "print(df2)\n",
        "\n",
        "# method 3 using seperate dictonaries\n",
        "\n",
        "c=[{\"1\":\"a\",\"2\":\"b\"},{\"1\":\"one\",\"2\":\"two\"}]\n",
        "df3=pd.DataFrame(c)\n",
        "print(df3)\n",
        "#decribing a data frame\n",
        "print(df.shape)   #only the number of rows and columns\n",
        "print(df.info())    #displays the columns names and data types\n",
        "# printing a data frame\n",
        "print(df.head(5))    #first 5 rows\n",
        "print(df.head(10))   #first 10 rows\n",
        "print(df.tail(5))    #last 5 rows\n",
        "\n",
        "# printing columnns\n",
        "\n",
        "df.MainBranch    #printing one column\n",
        "df['MainBranch']  #printing one column\n",
        "df[['MainBranch','JobSeek']]    #printing multiple columns\n",
        "df=pd.read_csv(\"survey_results_public.csv\",)\n",
        "# printing rows\n",
        "# loc==column\n",
        "#iloc == index integer\n",
        "print(df3)\n",
        "print(df3.loc[0]) #only row filter\n",
        "print(df3.loc[0],2)\n",
        "#df\n",
        "#df.loc[0:3] if there is no index this will work\n",
        "df.set_index('Respondent',inplace=True)\n",
        "\n",
        "\n",
        "df.iloc[0:3,[0,5]]\n",
        "\n",
        "# df.loc[0:3] gives an errror because there is an index\n",
        "# about indexes\n",
        "\n",
        "df.set_index('Student',inplace=True)\n",
        "\n",
        "#reset index\n",
        "df.reset_index(inplace=True)\n",
        "df.sort_index()\n",
        "#df.sort_index(ascending=False)\n",
        "# filtering data\n",
        "filt=(df['Student']==\"No\")\n",
        "df=df[filt]\n",
        "#print(df.Student)  #or\n",
        "#print(df.loc[filt,'Student'])\n",
        "filter1=(df['Student']=='No') & (df['Country']=='Canada')\n",
        "print(df.loc[filter1,['Student','Country']])\n",
        "\n",
        "    #or\n",
        "\n",
        "#df[df['Student']==\"No\"]\n",
        "#print(df)\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "K3kwK5DQsBOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Ag4MSgksawT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "\n",
        "importing data with null values\n",
        "agregate functions\n",
        "filling values\n",
        "dropping values\n",
        "group by\n",
        "\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "df=pd.read_csv('nyc_weather.csv',index_col=\"EST\")\n",
        "\n",
        "#parse dates changes column to date time index\n",
        "# replacing uneven nullvalues with common format Nan\n",
        "df=pd.read_csv('nyc_weather.csv',na_values=[\"not available\"])\n",
        "df=pd.read_csv('nyc_weather.csv',index_col=\"EST\",na_values={'Temperature':[\"not available\",'na'],'PrecipitationIn':['-1']},parse_dates=[\"EST\"])\n",
        "df\n",
        "\n",
        "# aggregate functions\n",
        "\n",
        "df['Temperature'].max()\n",
        "df['Humidity'].mean()\n",
        "df.describe\n",
        "df[df['Temperature']>=32]\n",
        "df[df['Temperature']==df[\"Temperature\"].max()]\n",
        "df[\"EST\"][df['Temperature']>=32]\n",
        "#Fill na\n",
        "# fill na replaces NAN values\n",
        "df.fillna(0) #replaces with Zero for all the columns\n",
        "df.fillna({'Temperature':df.Temperature.mean(),'Humidity':df.Humidity.mean()},inplace=True) # seperate for each columns\n",
        "df.Events.fillna(\"good\")\n",
        "\n",
        "new_df=df.fillna(method=\"ffill\",inplace=True)  # forward fill ___applys previous days values\n",
        "new_df=df.fillna(method=\"bfill\")  #backward fill ____apllys next days values\n",
        "new_df=df.fillna(method=\"bfill\",limit=1)\n",
        "new_df.Events.fillna(\"normal\",inplace=True)\n",
        "new_df\n",
        "#interpolate\n",
        "\n",
        "new_df=df.interpolate()\n",
        "new_df=df.interpolate(method=\"time\")\n",
        "new_df\n",
        "# dropping values\n",
        "\n",
        "new_df=df.dropna(how=\"all\") # removes row when every value of a row is null\n",
        "new_df=df.dropna()      #removes a row when even one values of a row is null\n",
        "new_df=df.dropna(thresh=2)\n",
        "#dropping duplictes\n",
        "new_df.drop_duplicates(inplace = True)\n",
        "g=new_df.groupby('Events')\n",
        "for Event,Event_df in g:\n",
        "    print(Event)\n",
        "    print(Event_df)\n",
        "g.max()\n",
        "g.describe()\n"
      ],
      "metadata": {
        "id": "tGFlsaZAsJ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "concatinating data frames\n",
        "merging data frames _______joins\n",
        "pivots\n",
        "\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "india_weather = pd.DataFrame({\n",
        "    \"city\": [\"mumbai\",\"delhi\",\"banglore\"],\n",
        "    \"temperature\": [32,45,30],\n",
        "    \"humidity\": [80, 60, 78]\n",
        "})\n",
        "us_weather = pd.DataFrame({\n",
        "    \"city\": [\"new york\",\"chicago\",\"orlando\"],\n",
        "    \"temperature\": [21,14,35],\n",
        "    \"humidity\": [68, 65, 75]\n",
        "})\n",
        "\n",
        "df=pd.concat([india_weather,us_weather],ignore_index=True) #igores index\n",
        "df1=pd.concat([india_weather,us_weather])           #vertically adds rows\n",
        "df2=pd.concat([india_weather,us_weather],axis=1)  #horiantly adds columns\n",
        "df3=pd.concat([india_weather,us_weather],keys=['india','us'])\n",
        "print(df)\n",
        "print(df1)\n",
        "print(df2)\n",
        "print(df3)\n",
        "df1 = pd.DataFrame({\n",
        "    \"city\": [\"new york\",\"chicago\",\"orlando\", \"baltimore\"],\n",
        "    \"temperature\": [21,14,35, 38],\n",
        "})\n",
        "print(df1)\n",
        "df2 = pd.DataFrame({\n",
        "    \"city\": [\"chicago\",\"new york\",\"san diego\"],\n",
        "    \"humidity\": [65,68,71],\n",
        "})\n",
        "print(df2)\n",
        "df3=pd.merge(df1,df2,on='city')  #performs innernjoin\n",
        "print(df3)\n",
        "df3=pd.merge(df1,df2,on='city',how='outer')  #performs outer join\n",
        "print(df3)\n",
        "df3=pd.merge(df1,df2,on='city',how='left')  #performs left join\n",
        "print(df3)\n",
        "df3=pd.merge(df1,df2,on='city',how='right',indicator=True)  #performs left join\n",
        "print(df3)\n",
        "df3=pd.merge(df1,df2,on='city',how='right',suffixes=('left','right'))\n",
        "print(df3)\n",
        "df=pd.read_csv(\"weather.csv\")\n",
        "df\n",
        "#pivots are used to shape and reshape data\n",
        "\n",
        "df.pivot(index=\"date\",columns=\"city\",values=\"humidity\")\n",
        "df.pivot(index=\"city\",columns=\"date\",values=\"humidity\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aBeSUXT5scyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('username.csv',delimiter=\";\")\n",
        "print(df)\n",
        "\n",
        "df.Username.str.upper()    #just displays\n",
        "df.Username=df.Username.str.upper()\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Mfp6Y0Ipshrz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}